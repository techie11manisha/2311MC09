{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfjYGejZ6NQs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from Informer.data_loaders import TimeSeriesDataset\n",
        "from Informer.models import Informer\n",
        "from Informer.utils import create_exponential_decay_lr_scheduler\n",
        "\n",
        "# Load the weather data\n",
        "weather_data = pd.read_csv('weather.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = MinMaxScaler()\n",
        "weather_data_scaled = scaler.fit_transform(weather_data)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train = weather_data_scaled[0:int(len(weather_data_scaled) * 0.8), :-1]\n",
        "y_train = weather_data_scaled[0:int(len(weather_data_scaled) * 0.8), -1]\n",
        "X_test = weather_data_scaled[int(len(weather_data_scaled) * 0.8):, :-1]\n",
        "y_test = weather_data_scaled[int(len(weather_data_scaled) * 0.8):, -1]\n",
        "\n",
        "# Create the ProbSparse Informer model\n",
        "probsparse_informer = Informer(\n",
        "    enc_in_channels=X_train.shape[1],\n",
        "    dec_in_channels=y_train.shape[1],\n",
        "    c=8,\n",
        "    d=64,\n",
        "    kernel_size=(1, 1),\n",
        "    dropout=0.1,\n",
        "    attention_type='probsparse'\n",
        ")\n",
        "\n",
        "# Create the Canonical Informer model\n",
        "canonical_informer = Informer(\n",
        "    enc_in_channels=X_train.shape[1],\n",
        "    dec_in_channels=y_train.shape[1],\n",
        "    c=8,\n",
        "    d=64,\n",
        "    kernel_size=(1, 1),\n",
        "    dropout=0.1,\n",
        "    attention_type='canonical'\n",
        ")\n",
        "\n",
        "# Train the ProbSparse Informer model\n",
        "probsparse_informer_lr_scheduler = create_exponential_decay_lr_scheduler(\n",
        "    probsparse_informer.optimizer,\n",
        "    start_lr=0.001,\n",
        "    end_lr=0.0001,\n",
        "    total_epochs=100\n",
        ")\n",
        "\n",
        "probsparse_informer.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    lr_scheduler=probsparse_informer_lr_scheduler,\n",
        "    num_epochs=100,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Train the Canonical Informer model\n",
        "canonical_informer_lr_scheduler = create_exponential_decay_lr_scheduler(\n",
        "    canonical_informer.optimizer,\n",
        "    start_lr=0.001,\n",
        "    end_lr=0.0001,\n",
        "    total_epochs=100\n",
        ")\n",
        "\n",
        "canonical_informer.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    lr_scheduler=canonical_informer_lr_scheduler,\n",
        "    num_epochs=100,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Evaluate the ProbSparse Informer model on the test set\n",
        "probsparse_informer_pred = probsparse_informer.predict(X_test)\n",
        "probsparse_informer_rmse = np.sqrt(np.mean((probsparse_informer_pred - y_test)**2))\n",
        "\n",
        "# Evaluate the Canonical Informer model on the test set\n",
        "canonical_informer_pred = canonical_informer.predict(X_test)\n",
        "canonical_informer_rmse = np.sqrt(np.mean((canonical_informer_pred - y_test)**2))\n",
        "\n",
        "# Print the results\n",
        "print('ProbSparse Informer RMSE:', probsparse_informer_rmse)\n",
        "print('Canonical Informer RMSE:', canonical_informer_rmse)\n"
      ]
    }
  ]
}